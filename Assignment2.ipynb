{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbb65023-3761-4ea7-b947-54d833f5f9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from PIL import Image\n",
    "from fastdtw import fastdtw\n",
    "from scipy.spatial.distance import euclidean\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.stats import kruskal\n",
    "import scikit_posthocs as sp\n",
    "import scipy.stats as stats\n",
    "\n",
    "from SimpleHRNet import SimpleHRNet\n",
    "from misc.visualization import draw_points_and_skeleton, joints_dict\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df1e34d6-eaec-491c-9b12-a7b4e62f4255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: 'cuda' - 1 GPU(s) will be used\n"
     ]
    }
   ],
   "source": [
    "#load model \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = SimpleHRNet(32, 17, \"./pose_hrnet_w32_256x192.pth\", device=device, multiperson=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a31d31bb-56b3-48a4-92e1-0ba855958384",
   "metadata": {},
   "outputs": [],
   "source": [
    "#video inferencing\n",
    "def process_video(video_path):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    video_path (str): Path to the input video file.\n",
    "\n",
    "    Returns:\n",
    "    list: List of Coco-joint data for each frame in the video.\n",
    "    \"\"\"\n",
    "    # List to store joints for each frame\n",
    "    all_joints_truth = []\n",
    "\n",
    "    # Open the video file\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "\n",
    "    if not video.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return []\n",
    "\n",
    "    # Get video properties\n",
    "    fps = video.get(cv2.CAP_PROP_FPS)\n",
    "    frame_width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # Loop over video frames\n",
    "    while True:\n",
    "        t = time.time()\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break  # End of video\n",
    "\n",
    "        # Make predictions on the current frame\n",
    "        joints = model.predict(frame) \n",
    "        all_joints_truth.append(joints[0])  # Store the joint data for this frame\n",
    "\n",
    "        # Draw joints and skeleton on the frame (optional)\n",
    "        pts = model.predict(frame)\n",
    "        person_ids = np.arange(len(pts), dtype=np.int32)\n",
    "\n",
    "        # Calculate and display framerate\n",
    "        fps = 1. / (time.time() - t)\n",
    "        print(f'\\rFramerate: {fps:.2f} fps, for {len(pts)} person(s)', end='')\n",
    "    print(\" \")    \n",
    "    # Release video capture\n",
    "    video.release()\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Return the list of joints for each frame\n",
    "    return all_joints_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2630c8-2a8e-41fe-8d43-1ba48e43a099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing exercise: push_up, Video: perfect.mp4\n",
      "Framerate: 7.82 fps, for 1 person(s) \n",
      "Processing exercise: push_up, Video: good_attempt.mp4\n",
      "Framerate: 5.67 fps, for 1 person(s) \n",
      "Processing exercise: push_up, Video: bad_attempt.mp4\n",
      "Framerate: 7.63 fps, for 1 person(s) \n",
      "Processing exercise: push_up, Video: almost.mp4\n",
      "Framerate: 6.83 fps, for 1 person(s) \n",
      "Processing exercise: pull_up, Video: perfect.mp4\n",
      "Framerate: 6.95 fps, for 1 person(s) \n",
      "Processing exercise: pull_up, Video: good_attempt.mp4\n",
      "Framerate: 7.39 fps, for 1 person(s) \n",
      "Processing exercise: pull_up, Video: bad_attempt.mp4\n",
      "Framerate: 7.03 fps, for 1 person(s)"
     ]
    }
   ],
   "source": [
    "# the list of exercise directories\n",
    "exercise_directories = ['push_up', 'pull_up', 'squat', 'lunge']  \n",
    "\n",
    "# the video names for each exercise\n",
    "video_names = ['perfect.mp4', 'good_attempt.mp4', 'bad_attempt.mp4', 'almost.mp4']\n",
    "\n",
    "# Initialize a dictionary to store the joint data for each exercise\n",
    "all_joints = {}\n",
    "\n",
    "# Loop through each exercise directory giving a dictionary of joint data for all exercises and all videos\n",
    "for exercise in exercise_directories:\n",
    "    # a list to store the joints for this exercise\n",
    "    all_joints[exercise] = {}\n",
    "\n",
    "    for video_name in video_names:\n",
    "        # Construct the full path to the video\n",
    "        video_path = os.path.join(exercise, video_name)\n",
    "        print(f\"Processing exercise: {exercise}, Video: {video_name}\")\n",
    "        # Check if the video exists \n",
    "        if os.path.exists(video_path):\n",
    "            # Process the video and get the joint data using the model\n",
    "            all_joints[exercise][video_name] = process_video(video_path)\n",
    "        else:\n",
    "            print(f\"Warning: {video_path} does not exist. Skipping.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c3b096-ad51-4315-b645-8b7c8acbcdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torso normalization\n",
    "def normalize_pose_sequence(pose_sequence):\n",
    "    normalized_sequence = []\n",
    "    left_shoulder_idx = 5  # Left shoulder index in COCO format\n",
    "    right_shoulder_idx = 6  # Right shoulder index in COCO format\n",
    "    \n",
    "    for frame in pose_sequence:\n",
    "        # Get the coordinates of the left and right shoulders\n",
    "        left_shoulder = frame[left_shoulder_idx, :2]  # Only x, y (ignore confidence)\n",
    "        right_shoulder = frame[right_shoulder_idx, :2]  # Only x, y (ignore confidence)\n",
    "        \n",
    "        # Calculate the torso center (midpoint between the shoulders)\n",
    "        torso_center_x = (left_shoulder[0] + right_shoulder[0]) / 2\n",
    "        torso_center_y = (left_shoulder[1] + right_shoulder[1]) / 2\n",
    "        \n",
    "        # Normalize the joint positions relative to the torso center\n",
    "        # Flatten the frame into a 1D vector: [joint1_x, joint1_y, joint2_x, joint2_y, ..., jointN_x, jointN_y]\n",
    "        normalized_frame = []\n",
    "        for joint in frame:\n",
    "            normalized_frame.extend([joint[0] - torso_center_x, joint[1] - torso_center_y])  # Only x, y values\n",
    "            \n",
    "        normalized_sequence.append(normalized_frame)\n",
    "    \n",
    "    return normalized_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74219ee-f60b-4d89-91d0-1c594ccff5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize all detected joints from inferencing phase using torso normalization\n",
    "def process_and_normalize_all_joints(all_joints):\n",
    "    normalized_all_joints = {}\n",
    "\n",
    "    # Loop through each exercise in all_joints\n",
    "    for exercise_name, video_data in all_joints.items():\n",
    "        normalized_all_joints[exercise_name] = {}  # Initialize the dictionary for each exercise\n",
    "\n",
    "        # Loop through each video within the exercise\n",
    "        for video_name, pose_sequence in video_data.items():\n",
    "            # Normalize the pose sequence for each video\n",
    "            normalized_sequence = normalize_pose_sequence(pose_sequence)\n",
    "            \n",
    "            # Store the normalized sequence in the dictionary under the respective exercise and video\n",
    "            normalized_all_joints[exercise_name][video_name] = normalized_sequence\n",
    "            print(f\"Normalized data for {exercise_name}/{video_name} added to dictionary.\")\n",
    "\n",
    "    return normalized_all_joints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f237256-1c58-4f5c-880e-54bea0221870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize and store the data in the dictionary\n",
    "normalized_all_joints = process_and_normalize_all_joints(all_joints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154e0a3a-fb2a-4832-b44f-44f56ab1a336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute DTW distance between two sequences\n",
    "def compute_dtw_distance(truth_sequence, attempt_sequence):\n",
    "    distance, _ = fastdtw(truth_sequence, attempt_sequence, dist=euclidean)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f7b33f-aa74-4526-bbae-13b71f5e6d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store DTW distances for all exercises\n",
    "dtw_results = {}\n",
    "\n",
    "# Function to compute DTW distances for all videos in all exercises\n",
    "def compute_dtw_for_all_exercises(normalized_all_joints):\n",
    "    global dtw_results\n",
    "    \n",
    "    # Loop through each exercise in normalized_all_joints\n",
    "    for exercise_name, video_data in normalized_all_joints.items():\n",
    "        dtw_results[exercise_name] = {}  # Initialize the dictionary for each exercise\n",
    "        \n",
    "        # Extract the ground truth sequence for the exercise\n",
    "        truth_sequence = video_data['perfect.mp4']  # perfect.mp4 is the ground truth\n",
    "        \n",
    "        # Compare with other videos (good attempt, bad attempt, almost perfect)\n",
    "        for video_name in ['good_attempt.mp4', 'bad_attempt.mp4', 'almost.mp4']:  \n",
    "            # Extract the sequence for the video\n",
    "            attempt_sequence = video_data[video_name]\n",
    "            \n",
    "            # Compute the DTW distance between the ground truth and the attempt\n",
    "            distance = compute_dtw_distance(truth_sequence, attempt_sequence)\n",
    "            \n",
    "            # Store the DTW distance in the dictionary\n",
    "            dtw_results[exercise_name][video_name] = distance\n",
    "            print(f\"DTW Distance for {exercise_name} - {video_name}: {distance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94a0153-619e-46bc-b797-bd4d48c9d261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute DTW distances for all exercises and videos\n",
    "compute_dtw_for_all_exercises(normalized_all_joints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb6f9f9-340a-43c3-87f6-8d4279175097",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code for Resampling with DTW: function to interpolate sequences to the same length\n",
    "def resample_sequence(sequence, target_length):\n",
    "    original_length = len(sequence)\n",
    "    x = np.linspace(0, 1, original_length)\n",
    "    interpolator = interp1d(x, sequence, axis=0, kind='linear')\n",
    "    new_x = np.linspace(0, 1, target_length)\n",
    "    return interpolator(new_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd804ff4-24b0-449a-adcb-2b448b457f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store resampled DTW distances for all exercises\n",
    "dtw_results_resampled = {}\n",
    "\n",
    "# Function to compute DTW distances for all videos in all exercises with resampling\n",
    "def compute_dtw_for_all_exercises_with_resampling(normalized_all_joints):\n",
    "    global dtw_results_resampled\n",
    "    \n",
    "    # Loop through each exercise in normalized_all_joints\n",
    "    for exercise_name, video_data in normalized_all_joints.items():\n",
    "        dtw_results_resampled[exercise_name] = {}  # Initialize the dictionary for each exercise\n",
    "        \n",
    "        # Extract the ground truth sequence for the exercise\n",
    "        truth_sequence = video_data['perfect.mp4']  # perfect.mp4 is the ground truth\n",
    "        \n",
    "        # Compare with other videos (good attempt, bad attempt, almost perfect)\n",
    "        for video_name in ['good_attempt.mp4', 'bad_attempt.mp4', 'almost.mp4']: \n",
    "            # Extract the sequence for the current video\n",
    "            attempt_sequence = video_data[video_name]\n",
    "            \n",
    "            # Set the target length to the maximum length of the ground truth and attempt sequence\n",
    "            target_length = max(len(truth_sequence), len(attempt_sequence))\n",
    "            \n",
    "            # Resample the ground truth sequence to the target length\n",
    "            truth_sequence_resampled = resample_sequence(truth_sequence, target_length)\n",
    "            \n",
    "            # Resample the attempt sequence to the target length\n",
    "            attempt_sequence_resampled = resample_sequence(attempt_sequence, target_length)\n",
    "            \n",
    "            # Compute the DTW distance between the resampled ground truth and the resampled attempt\n",
    "            distance = compute_dtw_distance(truth_sequence_resampled, attempt_sequence_resampled)\n",
    "            \n",
    "            # Store the DTW distance in the dictionary\n",
    "            dtw_results_resampled[exercise_name][video_name] = distance\n",
    "            print(f\"DTW Distance for {exercise_name} - {video_name} (Resampled): {distance}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5153af42-7b52-49c6-ad40-4fe532e1e1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute resampled DTW distances for all exercises and videos\n",
    "compute_dtw_for_all_exercises_with_resampling(normalized_all_joints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89f48651-4c78-497b-b8d4-eb79d927f526",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_dtw_results_side_by_side(dtw_results, dtw_results_resampled):\n",
    "    # Extract exercises and their DTW distances\n",
    "    exercises = list(dtw_results.keys())\n",
    "    \n",
    "    # a list of the video names\n",
    "    video_names = ['good_attempt.mp4', 'bad_attempt.mp4', 'almost.mp4']\n",
    "    \n",
    "    # Prepare data for plotting\n",
    "    distances_original = {video_name: [] for video_name in video_names}\n",
    "    distances_resampled = {video_name: [] for video_name in video_names}\n",
    "    \n",
    "    for exercise in exercises:\n",
    "        for video_name in video_names:\n",
    "            distances_original[video_name].append(dtw_results[exercise].get(video_name, np.nan))\n",
    "            distances_resampled[video_name].append(dtw_results_resampled[exercise].get(video_name, np.nan))\n",
    "    \n",
    "    # Create the figure with 2 subplots (side by side)\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "    # Bar width\n",
    "    bar_width = 0.25\n",
    "    index = np.arange(len(exercises))\n",
    "    \n",
    "    # Plot the original results \n",
    "    bars_original = []\n",
    "    for i, video_name in enumerate(video_names):\n",
    "        bars = ax1.bar(index + i * bar_width, distances_original[video_name], bar_width, label=video_name)\n",
    "        bars_original.append(bars)\n",
    "    \n",
    "    ax1.set_xlabel('Exercises')\n",
    "    ax1.set_ylabel('DTW Distance')\n",
    "    ax1.set_title('DTW Distance Comparison (Original Results)')\n",
    "    ax1.set_xticks(index + bar_width)\n",
    "    ax1.set_xticklabels(exercises, rotation=45, ha='right')\n",
    "    ax1.legend(handles=[bar[0] for bar in bars_original], labels=video_names)\n",
    "\n",
    "    # Plot the resampled results \n",
    "    bars_resampled = []\n",
    "    for i, video_name in enumerate(video_names):\n",
    "        bars = ax2.bar(index + i * bar_width, distances_resampled[video_name], bar_width, label=video_name)\n",
    "        bars_resampled.append(bars)\n",
    "    \n",
    "    ax2.set_xlabel('Exercises')\n",
    "    ax2.set_ylabel('DTW Distance')\n",
    "    ax2.set_title('DTW Distance Comparison (Resampled Results)')\n",
    "    ax2.set_xticks(index + bar_width)\n",
    "    ax2.set_xticklabels(exercises, rotation=45, ha='right')\n",
    "    ax2.legend(handles=[bar[0] for bar in bars_resampled], labels=video_names)\n",
    "\n",
    "    # Layout adjustment\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1ce6b1-bfe2-4e87-9248-27a76a54d03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_dtw_results_side_by_side(dtw_results, dtw_results_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4a2c3e-09dd-4981-a3c9-1c21cf951d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kruskal\n",
    "\n",
    "# Initialize lists to collect DTW distances grouped by video type\n",
    "good_attempts = []\n",
    "bad_attempts = []\n",
    "almost_attempts = []\n",
    "\n",
    "# Loop through all exercises and collect distances\n",
    "print(\"Collecting DTW distances per video type...\\n\")\n",
    "for exercise_name, video_scores in dtw_results.items():\n",
    "    print(f\"Exercise: {exercise_name}\")\n",
    "    good = video_scores['good_attempt.mp4']\n",
    "    bad = video_scores['bad_attempt.mp4']\n",
    "    almost = video_scores['almost.mp4']\n",
    "\n",
    "    print(f\"  Good Attempt:   {good}\")\n",
    "    print(f\"  Bad Attempt:    {bad}\")\n",
    "    print(f\"  Almost Attempt: {almost}\\n\")\n",
    "\n",
    "    good_attempts.append(good)\n",
    "    bad_attempts.append(bad)\n",
    "    almost_attempts.append(almost)\n",
    "\n",
    "# Show all grouped DTW distances\n",
    "print(\"Grouped DTW Distances:\")\n",
    "print(f\"Good Attempts:   {good_attempts}\")\n",
    "print(f\"Bad Attempts:    {bad_attempts}\")\n",
    "print(f\"Almost Attempts: {almost_attempts}\\n\")\n",
    "\n",
    "# Perform Kruskal-Wallis H-test\n",
    "statistic, p_value = kruskal(good_attempts, bad_attempts, almost_attempts)\n",
    "\n",
    "# Output results\n",
    "print(\"Kruskal-Wallis H-test result:\")\n",
    "print(f\"Statistic: {statistic}\")\n",
    "print(f\"P-value: {p_value:.5f}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"✅ There is a statistically significant difference between at least two groups.\")\n",
    "else:\n",
    "    print(\"❌ No statistically significant difference was found between the groups.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1700d74-b747-46f6-98c2-4e368e1c0c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flatten DTW values and create corresponding group labels\n",
    "dtw_values = []\n",
    "group_labels = []\n",
    "\n",
    "for exercise_name, video_scores in dtw_results.items():\n",
    "    dtw_values.extend([\n",
    "        video_scores['good_attempt.mp4'],\n",
    "        video_scores['bad_attempt.mp4'],\n",
    "        video_scores['almost.mp4']\n",
    "    ])\n",
    "    group_labels.extend([\n",
    "        'Good Attempt',\n",
    "        'Bad Attempt',\n",
    "        'Almost Attempt'\n",
    "    ])\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'dtw': dtw_values,\n",
    "    'group': group_labels\n",
    "})\n",
    "\n",
    "# Run Dunn’s test using the correct DataFrame-based input\n",
    "dunn_results = sp.posthoc_dunn(df, val_col='dtw', group_col='group', p_adjust='bonferroni')\n",
    "\n",
    "# Display the results\n",
    "print(\"Dunn's Post-hoc Test (with Bonferroni correction):\")\n",
    "print(dunn_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016e76f1-2918-4997-92ea-885cd60474eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(dunn_results, annot=True, cmap='coolwarm', fmt=\".3f\")\n",
    "plt.title(\"Dunn's Test Pairwise p-values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cd94db-abd4-4e51-aa7f-40b4ad9edcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to collect DTW distances grouped by video type\n",
    "good_attempts = []\n",
    "bad_attempts = []\n",
    "almost_attempts = []\n",
    "\n",
    "# Loop through all exercises and collect distances\n",
    "for exercise_name, video_scores in dtw_results_resampled.items():\n",
    "    good_attempts.append(video_scores['good_attempt.mp4'])\n",
    "    bad_attempts.append(video_scores['bad_attempt.mp4'])\n",
    "    almost_attempts.append(video_scores['almost.mp4'])\n",
    "\n",
    "# Perform Kruskal-Wallis H-test\n",
    "statistic, p_value = kruskal(good_attempts, bad_attempts, almost_attempts)\n",
    "\n",
    "# Output results\n",
    "print(\"Kruskal-Wallis H-test result:\")\n",
    "print(f\"Statistic: {statistic}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"There is a statistically significant difference between at least two groups.\")\n",
    "else:\n",
    "    print(\"No statistically significant difference was found between the groups.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
