{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e6e19b7-7a76-4316-8ebd-4d9e021ef5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essential Imports\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import pathlib\n",
    "import math\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from SimpleHRNet import SimpleHRNet\n",
    "from fastdtw import fastdtw\n",
    "from scipy.spatial.distance import euclidean\n",
    "from scipy.signal import find_peaks\n",
    "import scipy.ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ee4a028-1453-450b-bcfd-c76c98565fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constants and configuration set (including tuning ranges).\n",
      "Constants and configuration set.\n",
      "Baseline Directory: C:/Users/michel.marien_icarew/Documents/Priv√©/Opleiding/Mastervakken/Deep Neural Networks/Opdacht 2/baselines2\n",
      "Model location: C:\\Users\\michel.marien_icarew\\Documents\\Priv√©\\Opleiding\\Mastervakken\\Deep Neural Networks\\Opdacht 2\\simple-HRNet\\weights\\pose_hrnet_w48_256x192.pth\n",
      "Video to Recognize: C:/Users/michel.marien_icarew/Documents/Priv√©/Opleiding/Mastervakken/Deep Neural Networks/Opdacht 2/test_videos/test_excercise.mp4\n",
      "DTW Threshold: 500.0\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = pathlib.Path(\"C:/Users/michel.marien_icarew/Documents/Priv√©/Opleiding/Mastervakken/Deep Neural Networks/Opdacht 2/simple-HRNet/weights/pose_hrnet_w48_256x192.pth\") # Path to HRNet weights\n",
    "BASELINE_ROOT_DIR = \"C:/Users/michel.marien_icarew/Documents/Priv√©/Opleiding/Mastervakken/Deep Neural Networks/Opdacht 2/baselines2\"\n",
    "VIDEO_TO_RECOGNIZE_PATH = \"C:/Users/michel.marien_icarew/Documents/Priv√©/Opleiding/Mastervakken/Deep Neural Networks/Opdacht 2/test_videos/test_excercise.mp4\" # Video file to analyze\n",
    "\n",
    "EXPECTED_JOINT_COUNT = 17 \n",
    "JOINT_NAMES_LIST = [\"Nose\",\"Left Eye\",\"Right Eye\",\"Left Ear\",\"Right Ear\",\"Left Shoulder\",\n",
    "                    \"Right Shoulder\",\"Left Elbow\",\"Right Elbow\",\"Left Wrist\",\"Right Wrist\",\n",
    "                    \"Left Hip\",\"Right Hip\",\"Left Knee\",\"Right Knee\",\"Left Ankle\",\"Right Ankle\"]\n",
    "\n",
    "TARGET_REP_LENGTH = 100      # Fixed number of frames for timenormalized sequences\n",
    "DTW_DISTANCE_THRESHOLD = 500.0 # Max DTW distance to consider a match\n",
    "\n",
    "DEFAULT_SMOOTHING_WINDOW = 5#2 #5   # Frames for moving average smoothing\n",
    "DEFAULT_PEAK_PROMINENCE = 0.05#0.01 #0.05 # Relative prominence for peak detection (0.0 to 1.0)\n",
    "DEFAULT_PEAK_DISTANCE = 10#5#10     # Minimum frames between detected peaks/reps\n",
    "\n",
    "TUNING_PROMINENCE_RANGE = [0.02, 0.04, 0.06, 0.08, 0.10] # Example range\n",
    "TUNING_DISTANCE_RANGE = [5, 8, 10, 12, 15, 20]      # Example range\n",
    "\n",
    "print(\"Constants and configuration set (including tuning ranges).\")\n",
    "\n",
    "print(\"Constants and configuration set.\")\n",
    "print(f\"Baseline Directory: {BASELINE_ROOT_DIR}\")\n",
    "print(f\"Model location: {MODEL_PATH}\")\n",
    "print(f\"Video to Recognize: {VIDEO_TO_RECOGNIZE_PATH}\")\n",
    "print(f\"DTW Threshold: {DTW_DISTANCE_THRESHOLD}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dcb6426c-b910-492d-b321-740217d488ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "device: 'cpu'\n",
      "SimpleHRNet model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "HRNET_MODEL = None\n",
    "try:\n",
    "    HRNET_MODEL = SimpleHRNet(c=48, \n",
    "                              nof_joints=EXPECTED_JOINT_COUNT,\n",
    "                              checkpoint_path=MODEL_PATH,\n",
    "                              device=DEVICE,\n",
    "                              multiperson=False)\n",
    "    print(\"SimpleHRNet model loaded successfully.\")\n",
    "except NameError:\n",
    "    print(\"Error: SimpleHRNet class not found. Check import in Cell 1.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Model checkpoint file not found at {MODEL_PATH}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading SimpleHRNet model: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d11521f-dc25-4e33-984c-c1f2faa4705f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions defined.\n"
     ]
    }
   ],
   "source": [
    "def get_keypoint(frame_kps, kp_index):\n",
    "    \"\"\"Safely get keypoint coordinates (x, y) from a frame's keypoint array.\"\"\"\n",
    "    if frame_kps is not None and kp_index < frame_kps.shape[0]:\n",
    "        coords = frame_kps[kp_index, :2] # Take only x, y\n",
    "        if not np.isnan(coords).any():\n",
    "            return coords\n",
    "    return None\n",
    "\n",
    "def calculate_angle(p1, p2, p3):\n",
    "    \"\"\"Calculates the angle (in degrees) at p2 formed by p1p2p3.\"\"\"\n",
    "    if p1 is None or p2 is None or p3 is None: return None\n",
    "    v1, v2 = np.array(p1) - np.array(p2), np.array(p3) - np.array(p2)\n",
    "    mag1, mag2 = np.linalg.norm(v1), np.linalg.norm(v2)\n",
    "    if mag1 * mag2 == 0: return None\n",
    "    cos_angle = np.clip(np.dot(v1, v2) / (mag1 * mag2), 1.0, 1.0)\n",
    "    return np.degrees(np.arccos(cos_angle))\n",
    "\n",
    "def handle_nan_values(sequence):\n",
    "    \"\"\"Handles NaN values in a pose sequence (frames, coords). Removes frames containing any NaNs.\"\"\"\n",
    "    if sequence is None or sequence.ndim != 2 or sequence.shape[0] == 0:\n",
    "        return np.empty((0, sequence.shape[1] if sequence is not None and sequence.ndim == 2 else 0))\n",
    "    valid_frames_mask = ~np.isnan(sequence).any(axis=1)\n",
    "    return sequence[valid_frames_mask]\n",
    "\n",
    "def time_normalize_sequence(sequence, target_length):\n",
    "    \"\"\"Resamples a pose sequence (frames, coords) to a target length using linear interpolation.\"\"\"\n",
    "    if sequence is None or sequence.shape[0] < 2:\n",
    "        num_coords = sequence.shape[1] if sequence is not None and sequence.ndim == 2 else EXPECTED_JOINT_COUNT * 2\n",
    "        return np.full((target_length, num_coords), np.nan)\n",
    "\n",
    "    num_frames, num_coords = sequence.shape\n",
    "    original_indices = np.linspace(0, num_frames - 1, num_frames)\n",
    "    target_indices = np.linspace(0, num_frames - 1, target_length)\n",
    "    normalized_sequence = np.zeros((target_length, num_coords))\n",
    "\n",
    "    for j in range(num_coords):\n",
    "        valid_mask = ~np.isnan(sequence[:, j])\n",
    "        if np.sum(valid_mask) < 2:\n",
    "            normalized_sequence[:, j] = np.nan\n",
    "        else:\n",
    "            try:\n",
    "                normalized_sequence[:, j] = np.interp(target_indices, original_indices[valid_mask], sequence[valid_mask, j])\n",
    "            except Exception:\n",
    "                normalized_sequence[:, j] = np.nan\n",
    "\n",
    "    nan_mask = np.isnan(normalized_sequence)\n",
    "    if np.any(nan_mask):\n",
    "        idx = np.where(~nan_mask, np.arange(nan_mask.shape[0])[:, None], 0)\n",
    "        np.maximum.accumulate(idx, axis=0, out=idx)\n",
    "        normalized_sequence[nan_mask] = normalized_sequence[idx[nan_mask], np.nonzero(nan_mask)[1]]\n",
    "        nan_mask = np.isnan(normalized_sequence)\n",
    "        if np.any(nan_mask):\n",
    "            idx = np.where(~nan_mask, np.arange(nan_mask.shape[0])[:, None], nan_mask.shape[0] - 1)\n",
    "            idx = np.minimum.accumulate(idx[::1], axis=0)[::1]\n",
    "            normalized_sequence[nan_mask] = normalized_sequence[idx[nan_mask], np.nonzero(nan_mask)[1]]\n",
    "\n",
    "    return np.nan_to_num(normalized_sequence, nan=0.0)\n",
    "\n",
    "print(\"Helper functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bbf48e53-c429-4ae6-8c24-f71e148652d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining Core Processing Functions...\n",
      "Core processing functions defined (Cell 5 - Final Version).\n"
     ]
    }
   ],
   "source": [
    "def get_keypoint(frame_kps, kp_index):\n",
    "    \"\"\"Safely get keypoint coordinates (x, y) from a frame's keypoint array.\"\"\"\n",
    "    if frame_kps is not None and kp_index < frame_kps.shape[0]:\n",
    "        coords = frame_kps[kp_index, :2]\n",
    "        if not np.isnan(coords).any():\n",
    "            return coords\n",
    "    return None\n",
    "\n",
    "def calculate_angle(p1, p2, p3):\n",
    "    \"\"\"Calculates the angle (in degrees) at p2 formed by p1-p2-p3.\"\"\"\n",
    "    if p1 is None or p2 is None or p3 is None: return None\n",
    "    # Corrected vector calculation\n",
    "    v1, v2 = np.array(p1) - np.array(p2), np.array(p3) - np.array(p2)\n",
    "    mag1, mag2 = np.linalg.norm(v1), np.linalg.norm(v2)\n",
    "    if mag1 * mag2 == 0: return None\n",
    "    cos_angle = np.clip(np.dot(v1, v2) / (mag1 * mag2), -1.0, 1.0)\n",
    "    return np.degrees(np.arccos(cos_angle))\n",
    "\n",
    "def handle_nan_values(sequence):\n",
    "    \"\"\"Handles NaN values in a pose sequence (frames, coords). Removes frames containing any NaNs.\"\"\"\n",
    "    if sequence is None or sequence.ndim != 2 or sequence.shape[0] == 0:\n",
    "        return np.empty((0, sequence.shape[1] if sequence is not None and sequence.ndim == 2 else 0))\n",
    "    valid_frames_mask = ~np.isnan(sequence).any(axis=1)\n",
    "    return sequence[valid_frames_mask]\n",
    "\n",
    "def time_normalize_sequence(sequence, target_length):\n",
    "    \"\"\"Resamples a pose sequence (frames, coords) to a target length using linear interpolation.\"\"\"\n",
    "    if sequence is None or sequence.shape[0] < 2:\n",
    "        num_coords = sequence.shape[1] if sequence is not None and sequence.ndim == 2 else EXPECTED_JOINT_COUNT * 2\n",
    "        return np.full((target_length, num_coords), np.nan)\n",
    "\n",
    "    num_frames, num_coords = sequence.shape\n",
    "    original_indices = np.linspace(0, num_frames - 1, num_frames)\n",
    "    target_indices = np.linspace(0, num_frames - 1, target_length)\n",
    "    normalized_sequence = np.zeros((target_length, num_coords))\n",
    "\n",
    "    for j in range(num_coords):\n",
    "        valid_mask = ~np.isnan(sequence[:, j])\n",
    "        if np.sum(valid_mask) < 2:\n",
    "            normalized_sequence[:, j] = np.nan\n",
    "        else:\n",
    "            try:\n",
    "                normalized_sequence[:, j] = np.interp(target_indices, original_indices[valid_mask], sequence[valid_mask, j])\n",
    "            except Exception:\n",
    "                normalized_sequence[:, j] = np.nan\n",
    "\n",
    "    nan_mask = np.isnan(normalized_sequence)\n",
    "    if np.any(nan_mask):\n",
    "        idx_f = np.where(~nan_mask, np.arange(nan_mask.shape[0])[:, None], 0)\n",
    "        np.maximum.accumulate(idx_f, axis=0, out=idx_f)\n",
    "        valid_f_source_idx = idx_f[nan_mask] < normalized_sequence.shape[0]\n",
    "        nan_rows, nan_cols = np.nonzero(nan_mask)\n",
    "        valid_nan_rows = nan_rows[valid_f_source_idx]\n",
    "        valid_nan_cols = nan_cols[valid_f_source_idx]\n",
    "        valid_source_indices = idx_f[valid_nan_rows, valid_nan_cols] # Use valid indices only\n",
    "        normalized_sequence[valid_nan_rows, valid_nan_cols] = normalized_sequence[valid_source_indices, valid_nan_cols]\n",
    "\n",
    "        # Backward fill\n",
    "        nan_mask = np.isnan(normalized_sequence)\n",
    "        if np.any(nan_mask):\n",
    "             idx_b = np.where(~nan_mask, np.arange(nan_mask.shape[0])[:, None], nan_mask.shape[0] - 1)\n",
    "             idx_b = np.minimum.accumulate(idx_b[::-1], axis=0)[::-1]\n",
    "             valid_b_source_idx = idx_b[nan_mask] >= 0\n",
    "             nan_rows, nan_cols = np.nonzero(nan_mask)\n",
    "             valid_nan_rows = nan_rows[valid_b_source_idx]\n",
    "             valid_nan_cols = nan_cols[valid_b_source_idx]\n",
    "             valid_source_indices = idx_b[valid_nan_rows, valid_nan_cols] # Use valid indices only\n",
    "             normalized_sequence[valid_nan_rows, valid_nan_cols] = normalized_sequence[valid_source_indices, valid_nan_cols]\n",
    "\n",
    "    return np.nan_to_num(normalized_sequence, nan=0.0)\n",
    "\n",
    "def process_single_video(video_path, model, expected_joint_count=17):\n",
    "    \"\"\"Processes a single video, extracts joints, and returns a NumPy array (frames, num_coords).\"\"\"\n",
    "    if not os.path.exists(video_path):\n",
    "        print(f\"Error: Video file not found at {video_path}\")\n",
    "        return None\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    if not video.isOpened():\n",
    "        print(f\"Error: Could not open video {video_path}.\")\n",
    "        return None\n",
    "\n",
    "    video_joints, frame_count = [], 0\n",
    "    expected_coords = expected_joint_count * 2\n",
    "\n",
    "    while True:\n",
    "        ret, frame = video.read()\n",
    "        if not ret: break\n",
    "        try:\n",
    "            joints = model.predict(frame)\n",
    "            if joints is None or joints.shape[0] == 0 or joints.shape[1] != expected_joint_count:\n",
    "                frame_coords = np.full(expected_coords, np.nan)\n",
    "            else:\n",
    "                frame_coords = joints[0, :, :2].flatten()\n",
    "                if frame_coords.shape[0] != expected_coords:\n",
    "                    frame_coords = np.full(expected_coords, np.nan)\n",
    "        except Exception as e:\n",
    "            frame_coords = np.full(expected_coords, np.nan)\n",
    "        video_joints.append(frame_coords)\n",
    "        frame_count += 1\n",
    "    video.release()\n",
    "    return np.array(video_joints) if video_joints else None\n",
    "\n",
    "def normalize_pose_sequence(pose_sequence, joint_names, ref_joint1_name=\"Left Shoulder\", ref_joint2_name=\"Right Shoulder\"):\n",
    "    \"\"\"Spatially normalizes a pose sequence based on reference joints.\"\"\"\n",
    "    if pose_sequence is None or pose_sequence.shape[0] == 0: return np.array([])\n",
    "    try:\n",
    "        ref_joint1_idx, ref_joint2_idx = joint_names.index(ref_joint1_name), joint_names.index(ref_joint2_name)\n",
    "    except ValueError:\n",
    "        print(f\"Error: Reference joints '{ref_joint1_name}' or '{ref_joint2_name}' not found.\")\n",
    "        return np.full_like(pose_sequence, np.nan)\n",
    "\n",
    "    normalized_frames = []\n",
    "    num_coords = pose_sequence.shape[1]\n",
    "    if num_coords != len(joint_names) * 2:\n",
    "         print(f\"Warning: Mismatch between expected coords ({len(joint_names)*2}) and actual ({num_coords}) in normalize_pose_sequence.\")\n",
    "         if num_coords % 2 != 0: return np.full_like(pose_sequence, np.nan)\n",
    "\n",
    "    for frame in pose_sequence:\n",
    "        try:\n",
    "             frame_joints = frame.reshape(-1, 2)\n",
    "\n",
    "             if frame_joints.shape[0] != len(joint_names):\n",
    "                  normalized_frames.append(np.full(num_coords, np.nan))\n",
    "                  continue\n",
    "\n",
    "             ref1 = get_keypoint(frame_joints, ref_joint1_idx)\n",
    "             ref2 = get_keypoint(frame_joints, ref_joint2_idx)\n",
    "\n",
    "             if ref1 is None or ref2 is None:\n",
    "                 normalized_frames.append(np.full(num_coords, np.nan))\n",
    "                 continue\n",
    "\n",
    "             center = (np.array(ref1) + np.array(ref2)) / 2.0\n",
    "             scale = np.linalg.norm(np.array(ref1) - np.array(ref2))\n",
    "\n",
    "             if scale == 0 or np.isclose(scale, 0): \n",
    "                 normalized_frames.append(np.full(num_coords, np.nan))\n",
    "                 continue\n",
    "\n",
    "             norm_frame_joints = (frame_joints - center) / scale\n",
    "             normalized_frames.append(norm_frame_joints.flatten())\n",
    "\n",
    "        except ValueError as ve: \n",
    "            normalized_frames.append(np.full(num_coords, np.nan))\n",
    "            continue\n",
    "        except Exception as e: \n",
    "            normalized_frames.append(np.full(num_coords, np.nan))\n",
    "            continue\n",
    "\n",
    "    return np.array(normalized_frames)\n",
    "\n",
    "\n",
    "def _extract_trajectory_and_find_peaks(pose_sequence, exercise_label, joint_names, smoothing_window, prominence, distance):\n",
    "    \"\"\"Internal helper to get trajectory and find peaks with specific parameters.\"\"\"\n",
    "    if pose_sequence is None or pose_sequence.shape[0] < max(distance * 2, smoothing_window) : return None, []\n",
    "\n",
    "    trajectory, invert_for_valley = None, False\n",
    "    try: \n",
    "        if 'squat' in exercise_label.lower() or 'lunge' in exercise_label.lower():\n",
    "            lhip_idx, rhip_idx = joint_names.index('Left Hip'), joint_names.index('Right Hip')\n",
    "            lhip_y, rhip_y = pose_sequence[:, 2 * lhip_idx + 1], pose_sequence[:, 2 * rhip_idx + 1]\n",
    "            valid_mask = ~np.isnan(lhip_y) & ~np.isnan(rhip_y)\n",
    "            if not np.any(valid_mask): return None, [] # No valid frames\n",
    "            trajectory = np.nanmean([lhip_y[valid_mask], rhip_y[valid_mask]], axis=0) \n",
    "            trajectory = np.nanmean([pose_sequence[:, 2 * lhip_idx + 1], pose_sequence[:, 2 * rhip_idx + 1]], axis=0) \n",
    "            invert_for_valley = True\n",
    "        elif 'bicep_curl' in exercise_label.lower() or 'curl' in exercise_label.lower():\n",
    "             lshoulder_idx, lelbow_idx, lwrist_idx = joint_names.index('Left Shoulder'), joint_names.index('Left Elbow'), joint_names.index('Left Wrist')\n",
    "             angles = [calculate_angle(get_keypoint(f.reshape(-1,2), lshoulder_idx), get_keypoint(f.reshape(-1,2), lelbow_idx), get_keypoint(f.reshape(-1,2), lwrist_idx)) for f in pose_sequence]\n",
    "             trajectory = np.array([a if a is not None else np.nan for a in angles])\n",
    "             invert_for_valley = True\n",
    "        elif 'tricep pushdown' in exercise_label.lower():\n",
    "             lshoulder_idx, lelbow_idx, lwrist_idx = joint_names.index('Left Shoulder'), joint_names.index('Left Elbow'), joint_names.index('Left Wrist')\n",
    "             angles = [calculate_angle(get_keypoint(f.reshape(-1,2), lshoulder_idx), get_keypoint(f.reshape(-1,2), lelbow_idx), get_keypoint(f.reshape(-1,2), lwrist_idx)) for f in pose_sequence]\n",
    "             trajectory = np.array([a if a is not None else np.nan for a in angles])\n",
    "             invert_for_valley = False\n",
    "        elif 'tricep dips' in exercise_label.lower():\n",
    "             lshoulder_idx, rshoulder_idx = joint_names.index('Left Shoulder'), joint_names.index('Right Shoulder')\n",
    "             trajectory = np.nanmean([pose_sequence[:, 2 * lshoulder_idx + 1], pose_sequence[:, 2 * rshoulder_idx + 1]], axis=0)\n",
    "             invert_for_valley = True\n",
    "        else:\n",
    "             print(f\"Warning: Trajectory logic not defined for '{exercise_label}' in _extract_trajectory_and_find_peaks.\")\n",
    "             return None, []\n",
    "\n",
    "        if trajectory is None or trajectory.shape[0] == 0 or np.all(np.isnan(trajectory)): return None, []\n",
    "        nan_mask = np.isnan(trajectory)\n",
    "        if np.any(nan_mask):\n",
    "            indices = np.arange(len(trajectory))\n",
    "            valid_indices = indices[~nan_mask]\n",
    "            if len(valid_indices) < 2: return None, [] \n",
    "            trajectory[nan_mask] = np.interp(indices[nan_mask], valid_indices, trajectory[valid_indices])\n",
    "        # Check again after interpolation\n",
    "        if np.any(np.isnan(trajectory)):\n",
    "             trajectory = np.nan_to_num(trajectory, nan=np.nanmean(trajectory))\n",
    "\n",
    "        if invert_for_valley: trajectory = -trajectory\n",
    "\n",
    "    except (ValueError, IndexError) as e: return None, []\n",
    "    except NameError as e: return None, []\n",
    "    except Exception as e: return None, []\n",
    "\n",
    "    if len(trajectory) < smoothing_window: return trajectory, []\n",
    "    smoothed_trajectory = np.convolve(trajectory, np.ones(smoothing_window)/smoothing_window, mode='valid')\n",
    "\n",
    "    if smoothed_trajectory.shape[0] == 0: return trajectory, []\n",
    "    data_range = np.ptp(smoothed_trajectory)\n",
    "    required_prominence = data_range * prominence if data_range > 0 else 0.01\n",
    "\n",
    "    try:\n",
    "        smoothed_indices_offset = (len(trajectory) - len(smoothed_trajectory)) // 2 \n",
    "        peak_indices_smoothed, properties = find_peaks(smoothed_trajectory, prominence=required_prominence, distance=distance)\n",
    "        peak_indices_original = peak_indices_smoothed + smoothed_indices_offset\n",
    "        # Ensure indices are within bounds\n",
    "        peak_indices_original = peak_indices_original[(peak_indices_original >= 0) & (peak_indices_original < len(trajectory))]\n",
    "        return trajectory, peak_indices_original\n",
    "    except Exception: return trajectory, []\n",
    "\n",
    "\n",
    "def segment_repetitions(pose_sequence, exercise_label, joint_names, smoothing_window=DEFAULT_SMOOTHING_WINDOW, peak_prominence=DEFAULT_PEAK_PROMINENCE, peak_distance=DEFAULT_PEAK_DISTANCE):\n",
    "    \"\"\"Segments a pose sequence into individual repetitions.\"\"\"\n",
    "    _, peak_indices = _extract_trajectory_and_find_peaks(pose_sequence, exercise_label, joint_names, smoothing_window, peak_prominence, peak_distance)\n",
    "    if peak_indices is None or len(peak_indices) < 2: return []\n",
    "    repetitions = [pose_sequence[peak_indices[i]:peak_indices[i+1], :] for i in range(len(peak_indices) - 1)]\n",
    "    return [rep for rep in repetitions if rep.shape[0] > 1]\n",
    "\n",
    "\n",
    "def tune_counting_parameters(exercise_label, labeled_video_data, joint_names, prominence_range, distance_range):\n",
    "    \"\"\"Performs grid search to find optimal peak detection parameters.\"\"\"\n",
    "    print(f\"  Tuning repetition counting parameters for: {exercise_label}...\")\n",
    "    best_params = (DEFAULT_PEAK_PROMINENCE, DEFAULT_PEAK_DISTANCE)\n",
    "    min_total_error = float('inf')\n",
    "    if not labeled_video_data: return best_params\n",
    "\n",
    "    num_combinations = len(prominence_range) * len(distance_range)\n",
    "    print(f\"    Testing {num_combinations} parameter combinations...\")\n",
    "    default_error = 0\n",
    "\n",
    "    for sequence, true_reps in labeled_video_data:\n",
    "         _, peak_indices_def = _extract_trajectory_and_find_peaks(sequence, exercise_label, joint_names, DEFAULT_SMOOTHING_WINDOW, DEFAULT_PEAK_PROMINENCE, DEFAULT_PEAK_DISTANCE)\n",
    "         calc_reps_def = len(peak_indices_def) if peak_indices_def is not None else 0\n",
    "         default_error += abs(calc_reps_def - true_reps)\n",
    "\n",
    "    for p_idx, p in enumerate(prominence_range):\n",
    "        for d_idx, d in enumerate(distance_range):\n",
    "            current_total_error = 0\n",
    "            for sequence, true_reps in labeled_video_data:\n",
    "                _, peak_indices = _extract_trajectory_and_find_peaks(sequence, exercise_label, joint_names, DEFAULT_SMOOTHING_WINDOW, p, d)\n",
    "                calculated_reps = len(peak_indices) if peak_indices is not None else 0\n",
    "                current_total_error += abs(calculated_reps - true_reps)\n",
    "            if current_total_error < min_total_error:\n",
    "                min_total_error = current_total_error\n",
    "                best_params = (p, d)\n",
    "            if min_total_error == 0: break\n",
    "        if min_total_error == 0: break\n",
    "\n",
    "\n",
    "    print(f\"    Tuning complete. Best Params: P={best_params[0]:.3f}, D={best_params[1]}, Min Error={min_total_error}. (Default Error={default_error})\")\n",
    "    return best_params\n",
    "\n",
    "\n",
    "def load_baseline_data(baseline_root_dir, hrnet_model, joint_names, target_rep_length, prominence_range, distance_range,\n",
    "                       threshold_std_multiplier=2.0, min_reps_for_threshold=3):\n",
    "    \"\"\"Loads baselines, tunes rep counting params, averages sequences, AND calculates derived thresholds.\"\"\"\n",
    "    averaged_baseline_data, tuned_counting_params, exercise_specific_thresholds = {}, {}, {}\n",
    "    start_time_total = time.time()\n",
    "    print(f\"Loading, Tuning, Averaging Baselines, and Deriving Thresholds from: {baseline_root_dir}\")\n",
    "    if not os.path.isdir(baseline_root_dir): return averaged_baseline_data, tuned_counting_params, exercise_specific_thresholds\n",
    "\n",
    "    for exercise_label in sorted(os.listdir(baseline_root_dir)):\n",
    "        exercise_folder_path = os.path.join(baseline_root_dir, exercise_label)\n",
    "        if not os.path.isdir(exercise_folder_path): continue\n",
    "        print(f\"\\nProcessing baseline exercise: {exercise_label}\")\n",
    "        all_normalized_reps_for_exercise, labeled_data_for_tuning = [], []\n",
    "        video_files = sorted([f for f in os.listdir(exercise_folder_path) if f.lower().endswith(('.mp4', '.avi', '.mov'))])\n",
    "\n",
    "        for video_file in video_files:\n",
    "            video_path = os.path.join(exercise_folder_path, video_file)\n",
    "            true_reps = None\n",
    "            match = re.search(r'_(\\d+)reps', video_file, re.IGNORECASE)\n",
    "            if match: true_reps = int(match.group(1))\n",
    "\n",
    "            raw_seq = process_single_video(video_path, hrnet_model, EXPECTED_JOINT_COUNT)\n",
    "            if raw_seq is None or raw_seq.shape[0] == 0: continue\n",
    "            spatially_norm_seq = normalize_pose_sequence(raw_seq, joint_names)\n",
    "            if spatially_norm_seq is None or np.all(np.isnan(spatially_norm_seq)): continue\n",
    "            cleaned_seq = handle_nan_values(spatially_norm_seq)\n",
    "            if cleaned_seq.shape[0] < 2: continue\n",
    "            if true_reps is not None: labeled_data_for_tuning.append((cleaned_seq, true_reps))\n",
    "\n",
    "            repetitions = segment_repetitions(cleaned_seq, exercise_label, joint_names)\n",
    "            for rep_segment in repetitions:\n",
    "                if rep_segment is not None and rep_segment.shape[0] >= 2:\n",
    "                    time_norm_rep = time_normalize_sequence(rep_segment, target_rep_length)\n",
    "                    if not np.isnan(time_norm_rep).all(): all_normalized_reps_for_exercise.append(time_norm_rep)\n",
    "\n",
    "        if labeled_data_for_tuning:\n",
    "            tuned_p, tuned_d = tune_counting_parameters(exercise_label, labeled_data_for_tuning, joint_names, prominence_range, distance_range)\n",
    "            tuned_counting_params[exercise_label] = (tuned_p, tuned_d)\n",
    "        else: tuned_counting_params[exercise_label] = (DEFAULT_PEAK_PROMINENCE, DEFAULT_PEAK_DISTANCE)\n",
    "\n",
    "        averaged_sequence = None\n",
    "        if len(all_normalized_reps_for_exercise) > 0:\n",
    "            reps_stack = np.stack(all_normalized_reps_for_exercise, axis=0)\n",
    "            averaged_sequence = np.nanmean(reps_stack, axis=0)\n",
    "            averaged_baseline_data[exercise_label] = np.nan_to_num(averaged_sequence, nan=0.0)\n",
    "        else: exercise_specific_thresholds[exercise_label] = None; continue\n",
    "\n",
    "        derived_threshold = None\n",
    "        if averaged_sequence is not None and len(all_normalized_reps_for_exercise) >= min_reps_for_threshold:\n",
    "            intra_distances = []\n",
    "            safe_avg = np.nan_to_num(averaged_sequence, nan=0.0)\n",
    "            for norm_rep in all_normalized_reps_for_exercise:\n",
    "                safe_rep = np.nan_to_num(norm_rep, nan=0.0)\n",
    "                if safe_rep.shape == safe_avg.shape:\n",
    "                    try: dist, _ = fastdtw(safe_rep, safe_avg, dist=euclidean); intra_distances.append(dist)\n",
    "                    except Exception: pass \n",
    "            if len(intra_distances) >= min_reps_for_threshold:\n",
    "                 mean_dist, std_dist = np.mean(intra_distances), np.std(intra_distances)\n",
    "                 derived_threshold = mean_dist + threshold_std_multiplier * std_dist\n",
    "                 print(f\"    Derived Threshold for {exercise_label}: {derived_threshold:.2f} (Mean={mean_dist:.2f}, Std={std_dist:.2f})\")\n",
    "        exercise_specific_thresholds[exercise_label] = derived_threshold\n",
    "\n",
    "    print(f\"\\nBaseline processing complete in {time.time() - start_time_total:.2f}s.\")\n",
    "    print(f\"Averaged baselines: {list(averaged_baseline_data.keys())}\")\n",
    "    print(f\"Tuned count params: {tuned_counting_params}\")\n",
    "    print(f\"Derived thresholds: {exercise_specific_thresholds}\")\n",
    "    return averaged_baseline_data, tuned_counting_params, exercise_specific_thresholds\n",
    "\n",
    "\n",
    "def count_repetitions(pose_sequence, exercise_label, joint_names, prominence=DEFAULT_PEAK_PROMINENCE, distance=DEFAULT_PEAK_DISTANCE, smoothing_window=DEFAULT_SMOOTHING_WINDOW):\n",
    "    \"\"\"Counts repetitions using the core helper logic with specified parameters.\"\"\"\n",
    "    _, peak_indices = _extract_trajectory_and_find_peaks(pose_sequence, exercise_label, joint_names, smoothing_window, prominence, distance)\n",
    "    return len(peak_indices) if peak_indices is not None else 0\n",
    "\n",
    "\n",
    "def recognize_exercise(new_video_path, averaged_baseline_data, hrnet_model, joint_names, distance_threshold, target_rep_length, tuned_counting_params):\n",
    "    \"\"\"Recognizes exercise using tuned segmentation and per-rep comparison.\"\"\"\n",
    "    print(f\"\\n--- Recognizing Exercise (Per Repetition / Tuned Seg) for: {os.path.basename(new_video_path)} ---\")\n",
    "    start_time = time.time()\n",
    "    if tuned_counting_params is None: tuned_counting_params = {}\n",
    "    default_p, default_d = DEFAULT_PEAK_PROMINENCE, DEFAULT_PEAK_DISTANCE\n",
    "\n",
    "    new_raw_seq = process_single_video(new_video_path, hrnet_model, EXPECTED_JOINT_COUNT)\n",
    "    if new_raw_seq is None or new_raw_seq.shape[0] == 0: return [], 0\n",
    "    new_spatially_norm_seq = normalize_pose_sequence(new_raw_seq, joint_names)\n",
    "    if new_spatially_norm_seq is None or np.all(np.isnan(new_spatially_norm_seq)): return [], 0\n",
    "    new_sequence_clean = handle_nan_values(new_spatially_norm_seq)\n",
    "    if new_sequence_clean.shape[0] < 2: return [], 0\n",
    "    new_sequence_time_norm = time_normalize_sequence(new_sequence_clean, target_rep_length)\n",
    "    if np.isnan(new_sequence_time_norm).all(): return [], 0\n",
    "    new_sequence_time_norm = np.nan_to_num(new_sequence_time_norm, nan=0.0)\n",
    "\n",
    "    initial_min_distance, initial_best_label = float('inf'), None\n",
    "    segment_p, segment_d = default_p, default_d\n",
    "    segment_label_guess = 'unknown'\n",
    "    if not averaged_baseline_data: print(\"Error: No baseline data for initial guess.\"); return [], 0\n",
    "    for ex_label, avg_base_seq in averaged_baseline_data.items():\n",
    "        if new_sequence_time_norm.shape != avg_base_seq.shape: continue\n",
    "        safe_base = np.nan_to_num(avg_base_seq, nan=0.0)\n",
    "        try: dist, _ = fastdtw(new_sequence_time_norm, safe_base, dist=euclidean)\n",
    "        except Exception: continue\n",
    "        if dist < initial_min_distance: initial_min_distance, initial_best_label = dist, ex_label\n",
    "\n",
    "    if initial_best_label and initial_min_distance < distance_threshold:\n",
    "        tuned_p, tuned_d = tuned_counting_params.get(initial_best_label, (default_p, default_d))\n",
    "        segment_p, segment_d = tuned_p, tuned_d\n",
    "        segment_label_guess = initial_best_label\n",
    "        print(f\"  Initial guess: {initial_best_label}. Using its tuned params for segmentation (P={segment_p:.3f}, D={segment_d}).\")\n",
    "    else:\n",
    "        print(f\"  Initial guess inconclusive. Using default params for segmentation.\")\n",
    "        if initial_best_label: segment_label_guess = initial_best_label\n",
    "\n",
    "    test_repetitions = segment_repetitions(new_sequence_clean, segment_label_guess, joint_names, peak_prominence=segment_p, peak_distance=segment_d)\n",
    "    num_detected_reps = len(test_repetitions)\n",
    "    print(f\"  Detected {num_detected_reps} potential repetitions in test video.\")\n",
    "    if num_detected_reps == 0: return [], 0\n",
    "\n",
    "    repetition_results = []\n",
    "    print(\"  Comparing each detected repetition against averaged baselines...\")\n",
    "    for i, rep_segment in enumerate(test_repetitions):\n",
    "        if rep_segment is None or rep_segment.shape[0] < 2:\n",
    "             repetition_results.append( (i+1, \"Error: Invalid Segment\", float('inf')) ); continue\n",
    "        time_norm_rep_segment = time_normalize_sequence(rep_segment, target_rep_length)\n",
    "        if np.isnan(time_norm_rep_segment).all():\n",
    "            repetition_results.append( (i+1, \"Error: Time Norm Failed\", float('inf')) ); continue\n",
    "        time_norm_rep_segment = np.nan_to_num(time_norm_rep_segment, nan=0.0)\n",
    "\n",
    "        min_rep_distance, best_rep_label_for_this_rep = float('inf'), None\n",
    "        for exercise_label, avg_baseline_seq in averaged_baseline_data.items():\n",
    "            if time_norm_rep_segment.shape != avg_baseline_seq.shape: continue\n",
    "            safe_baseline = np.nan_to_num(avg_baseline_seq, nan=0.0)\n",
    "            try: distance, _ = fastdtw(time_norm_rep_segment, safe_baseline, dist=euclidean)\n",
    "            except Exception: continue\n",
    "            if distance < min_rep_distance: min_rep_distance, best_rep_label_for_this_rep = distance, exercise_label\n",
    "\n",
    "        matched_label_for_rep = \"No Match / Inconclusive\"\n",
    "        if best_rep_label_for_this_rep and min_rep_distance < distance_threshold:\n",
    "            matched_label_for_rep = best_rep_label_for_this_rep\n",
    "        repetition_results.append( (i+1, matched_label_for_rep, min_rep_distance) )\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"--- Recognition finished in {end_time - start_time:.2f}s ---\")\n",
    "    return repetition_results, num_detected_reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6466ce65-7903-4244-9c67-99596f2727b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Running Configuration PreCheck \n",
      "‚úÖ MODEL_PATH: Found ('pose_hrnet_w48_256x192.pth').\n",
      "‚úÖ BASELINE_ROOT_DIR: Found ('C:/Users/michel.marien_icarew/Documents/Priv√©/Opleiding/Mastervakken/Deep Neural Networks/Opdacht 2/baselines2').\n",
      "‚úÖ VIDEO_TO_RECOGNIZE_PATH: Found ('test_excercise.mp4').\n",
      "‚úÖ DTW_DISTANCE_THRESHOLD: Set (500.0).\n",
      "‚úÖ TARGET_REP_LENGTH: Set (100).\n",
      "‚úÖ EXPECTED_JOINT_COUNT: Set (17).\n",
      "‚úÖ JOINT_NAMES_LIST: Defined with correct length (17).\n",
      "‚úÖ HRNET_MODEL: Loaded.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "print(\" Running Configuration PreCheck \")\n",
    "config_ok = True\n",
    "error_messages = []\n",
    "\n",
    "if 'MODEL_PATH' not in locals() or not MODEL_PATH:\n",
    "    error_messages.append(\"‚ùå MODEL_PATH: Not defined.\")\n",
    "    config_ok = False\n",
    "elif not os.path.exists(MODEL_PATH):\n",
    "    error_messages.append(f\"‚ùå MODEL_PATH: File not found at '{MODEL_PATH}'.\")\n",
    "    config_ok = False\n",
    "else:\n",
    "    print(f\"‚úÖ MODEL_PATH: Found ('{os.path.basename(MODEL_PATH)}').\")\n",
    "\n",
    "if 'BASELINE_ROOT_DIR' not in locals() or not BASELINE_ROOT_DIR:\n",
    "    error_messages.append(\"‚ùå BASELINE_ROOT_DIR: Not defined.\")\n",
    "    config_ok = False\n",
    "elif not os.path.isdir(BASELINE_ROOT_DIR):\n",
    "    error_messages.append(f\"‚ùå BASELINE_ROOT_DIR: Directory not found at '{BASELINE_ROOT_DIR}'. Please create it or correct the path.\")\n",
    "    config_ok = False\n",
    "else:\n",
    "    print(f\"‚úÖ BASELINE_ROOT_DIR: Found ('{BASELINE_ROOT_DIR}').\")\n",
    "\n",
    "if 'VIDEO_TO_RECOGNIZE_PATH' not in locals() or not VIDEO_TO_RECOGNIZE_PATH:\n",
    "    error_messages.append(\"‚ùå VIDEO_TO_RECOGNIZE_PATH: Not defined.\")\n",
    "    config_ok = False\n",
    "elif not os.path.exists(VIDEO_TO_RECOGNIZE_PATH):\n",
    "    error_messages.append(f\"‚ùå VIDEO_TO_RECOGNIZE_PATH: File not found at '{VIDEO_TO_RECOGNIZE_PATH}'.\")\n",
    "    config_ok = False\n",
    "else:\n",
    "    print(f\"‚úÖ VIDEO_TO_RECOGNIZE_PATH: Found ('{os.path.basename(VIDEO_TO_RECOGNIZE_PATH)}').\")\n",
    "\n",
    "if 'DTW_DISTANCE_THRESHOLD' not in locals() or not isinstance(DTW_DISTANCE_THRESHOLD, (int, float, np.number)) or np.isnan(DTW_DISTANCE_THRESHOLD):\n",
    "    error_messages.append(\"‚ùå DTW_DISTANCE_THRESHOLD: Not defined or not a valid number.\")\n",
    "    config_ok = False\n",
    "else:\n",
    "    print(f\"‚úÖ DTW_DISTANCE_THRESHOLD: Set ({DTW_DISTANCE_THRESHOLD}).\")\n",
    "\n",
    "if 'TARGET_REP_LENGTH' not in locals() or not isinstance(TARGET_REP_LENGTH, int) or TARGET_REP_LENGTH <= 0:\n",
    "    error_messages.append(\"‚ùå TARGET_REP_LENGTH: Not defined or not a positive integer.\")\n",
    "    config_ok = False\n",
    "else:\n",
    "    print(f\"‚úÖ TARGET_REP_LENGTH: Set ({TARGET_REP_LENGTH}).\")\n",
    "\n",
    "if 'EXPECTED_JOINT_COUNT' not in locals() or not isinstance(EXPECTED_JOINT_COUNT, int) or EXPECTED_JOINT_COUNT <= 0:\n",
    "    error_messages.append(\"‚ùå EXPECTED_JOINT_COUNT: Not defined or not a positive integer.\")\n",
    "    config_ok = False\n",
    "else:\n",
    "    print(f\"‚úÖ EXPECTED_JOINT_COUNT: Set ({EXPECTED_JOINT_COUNT}).\")\n",
    "    if 'JOINT_NAMES_LIST' not in locals() or not isinstance(JOINT_NAMES_LIST, list):\n",
    "        error_messages.append(\"‚ùå JOINT_NAMES_LIST: Not defined or not a list.\")\n",
    "        config_ok = False\n",
    "    elif len(JOINT_NAMES_LIST) != EXPECTED_JOINT_COUNT:\n",
    "        error_messages.append(f\"‚ùå JOINT_NAMES_LIST: Length ({len(JOINT_NAMES_LIST)}) does not match EXPECTED_JOINT_COUNT ({EXPECTED_JOINT_COUNT}).\")\n",
    "        config_ok = False\n",
    "    else:\n",
    "        print(f\"‚úÖ JOINT_NAMES_LIST: Defined with correct length ({len(JOINT_NAMES_LIST)}).\")\n",
    "if 'HRNET_MODEL' not in locals() or HRNET_MODEL is None:\n",
    "     error_messages.append(\"‚ùå HRNET_MODEL: Model was not loaded successfully in Cell 3.\")\n",
    "     config_ok = False\n",
    "else:\n",
    "     print(\"‚úÖ HRNET_MODEL: Loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "00125ec4-ab74-4cac-916c-2f2da4fb3be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Loading Baselines, Tuning Params, Deriving Thresholds\n",
      "Loading, Tuning, Averaging Baselines, and Deriving Thresholds from: C:/Users/michel.marien_icarew/Documents/Priv√©/Opleiding/Mastervakken/Deep Neural Networks/Opdacht 2/baselines2\n",
      "\n",
      "Processing baseline exercise: tricep Pushdown\n",
      "  Tuning repetition counting parameters for: tricep Pushdown...\n",
      "    Testing 30 parameter combinations...\n",
      "    Tuning complete. Best Params: P=0.080, D=15, Min Error=2. (Default Error=6)\n",
      "    Derived Threshold for tricep Pushdown: 6002.86 (Mean=2258.88, Std=1871.99)\n",
      "\n",
      "Processing baseline exercise: tricep dips\n",
      "  Tuning repetition counting parameters for: tricep dips...\n",
      "    Testing 30 parameter combinations...\n",
      "    Tuning complete. Best Params: P=0.080, D=20, Min Error=10. (Default Error=31)\n",
      "    Derived Threshold for tricep dips: 2026.38 (Mean=1014.17, Std=506.10)\n",
      "\n",
      "Baseline processing complete in 1889.20s.\n",
      "Averaged baselines: ['tricep Pushdown', 'tricep dips']\n",
      "Tuned count params: {'tricep Pushdown': (0.08, 15), 'tricep dips': (0.08, 20)}\n",
      "Derived thresholds: {'tricep Pushdown': 6002.864533559525, 'tricep dips': 2026.3825940640704}\n",
      "\n",
      " Baseline Data Loaded, Tuned, Thresholds Derived Successfully  üëç\n",
      "Loaded exercises: ['tricep Pushdown', 'tricep dips']\n"
     ]
    }
   ],
   "source": [
    "if 'HRNET_MODEL' not in locals() or HRNET_MODEL is None:\n",
    "    print(\"HRNet Model not loaded. Please run Cell 3 successfully first.\")\n",
    "elif 'config_ok' not in locals() or not config_ok:\n",
    "    print(\"Configuration check in Cell 5.5 failed. Please fix issues before running baseline loading.\")\n",
    "\n",
    "else:\n",
    "    print(\"Step 1: Loading Baselines, Tuning Params, Deriving Thresholds\") \n",
    "\n",
    "    averaged_baselines, tuned_params, derived_thresholds = load_baseline_data(\n",
    "        BASELINE_ROOT_DIR,\n",
    "        HRNET_MODEL,\n",
    "        JOINT_NAMES_LIST,\n",
    "        TARGET_REP_LENGTH,\n",
    "        TUNING_PROMINENCE_RANGE,\n",
    "        TUNING_DISTANCE_RANGE,\n",
    "        threshold_std_multiplier=2.0,\n",
    "        min_reps_for_threshold=3\n",
    "    )\n",
    "\n",
    "    if averaged_baselines and tuned_params and derived_thresholds:\n",
    "        print(\"\\n Baseline Data Loaded, Tuned, Thresholds Derived Successfully  üëç\")\n",
    "        print(f\"Loaded exercises: {list(averaged_baselines.keys())}\")\n",
    "    else:\n",
    "        print(\"\\n Baseline Data Processing Failed  üëé\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7c17a2cd-6d02-4598-b633-b4b37465bd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "DTW_DISTANCE_THRESHOLD = 7000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7910509c-2d9a-409e-8993-d16d4f5500c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================\n",
      "    Step 2: Recognizing Exercise in Video (Per Rep) \n",
      "    Video: test_excercise.mp4 \n",
      "==============================================\n",
      "\n",
      "--- Recognizing Exercise (Per Repetition / Tuned Seg) for: test_excercise.mp4 ---\n",
      "  Initial guess: tricep dips. Using its tuned params for segmentation (P=0.080, D=20).\n",
      "  Detected 0 potential repetitions in test video.\n",
      "\n",
      "==============================================\n",
      "    FINAL RESULT for test_excercise.mp4\n",
      "==============================================\n",
      "  Detected 0 Repetitions (using tuned segmentation parameters where possible).\n",
      "  No valid repetition results to display (segmentation might have failed or video was problematic).\n",
      "==============================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "video_to_test = VIDEO_TO_RECOGNIZE_PATH \n",
    "proceed_to_recognition = True\n",
    "\n",
    "if proceed_to_recognition:\n",
    "    print(\"==============================================\")\n",
    "    print(f\"    Step 2: Recognizing Exercise in Video (Per Rep) \")\n",
    "    print(f\"    Video: {os.path.basename(video_to_test)} \")\n",
    "    print(\"==============================================\")\n",
    "\n",
    "    list_of_rep_results, total_reps_detected = recognize_exercise(\n",
    "        video_to_test,\n",
    "        averaged_baselines,\n",
    "        HRNET_MODEL,\n",
    "        JOINT_NAMES_LIST,\n",
    "        DTW_DISTANCE_THRESHOLD,\n",
    "        TARGET_REP_LENGTH,\n",
    "        tuned_params\n",
    "    )\n",
    "\n",
    "    print(f\"FINAL RESULT for {os.path.basename(video_to_test)}\")\n",
    "\n",
    "    print(f\"Detected {total_reps_detected} Repetitions (using tuned segmentation parameters where possible).\")\n",
    "\n",
    "    if not list_of_rep_results:\n",
    "        print(\"No valid repetition results to display (segmentation might have failed)\")\n",
    "    else:\n",
    "        print(\"\\n  --- Per-Repetition Analysis ---\")\n",
    "        match_counts = {}\n",
    "        successful_reps = 0\n",
    "        for rep_index, matched_label, min_distance in list_of_rep_results:\n",
    "            status = \"\"\n",
    "            if matched_label.startswith(\"Error\"):\n",
    "                status = f\"-> {matched_label}\"\n",
    "            elif matched_label == \"No Match / Inconclusive\":\n",
    "                status = f\"-> No Match (Min Dist: {min_distance:.2f} >= {DTW_DISTANCE_THRESHOLD})\"\n",
    "            else:\n",
    "                status = f\"-> Match: {matched_label} (Dist: {min_distance:.2f})\"\n",
    "                match_counts[matched_label] = match_counts.get(matched_label, 0) + 1\n",
    "                successful_reps += 1\n",
    "\n",
    "            print(f\"    Rep {rep_index}: {status}\")\n",
    "\n",
    "        if successful_reps > 0:\n",
    "             if match_counts:\n",
    "                 majority_label = max(match_counts, key=match_counts.get)\n",
    "                 majority_count = match_counts[majority_label]\n",
    "                 print(f\"  Overall Predominant Match: {majority_label} ({majority_count}/{successful_reps} successfully matched reps)\")\n",
    "             else:\n",
    "                  print(\"No specific exercises were matched successfully.\")\n",
    "             print(f\"  Total Reps Successfully Matched (below threshold): {successful_reps} / {total_reps_detected}\")\n",
    "        else:\n",
    "             print(\"No repetitions were matched\")\n",
    "\n",
    "else:\n",
    "    for msg in error_messages:\n",
    "        print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bfe235-fa4c-4cc6-94f4-c9615dc84b82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
